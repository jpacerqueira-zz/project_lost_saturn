{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrating from Spark to BigQuery via Dataproc -- Part 5\n",
    "\n",
    "* [Part 1](01_spark.ipynb): The original Spark code, now running on Dataproc (lift-and-shift).\n",
    "* [Part 2](02_gcs.ipynb): Replace HDFS by Google Cloud Storage. This enables job-specific-clusters. (cloud-native)\n",
    "* [Part 3](03_automate.ipynb): Automate everything, so that we can run in a job-specific cluster. (cloud-optimized)\n",
    "* [Part 4](04_bigquery.ipynb): Load CSV into BigQuery, use BigQuery. (modernize)\n",
    "* [Part 5](05_functions.ipynb): Using Cloud Functions, launch analysis every time there is a new file in the bucket. (serverless)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catch-up cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Dataset\n",
      "'qwiklabs-gcp-576b6b9a967fad32:sparktobq' already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2019-08-01 09:58:21--  http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\n",
      "Resolving kdd.ics.uci.edu (kdd.ics.uci.edu)... 128.195.1.86\n",
      "Connecting to kdd.ics.uci.edu (kdd.ics.uci.edu)|128.195.1.86|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2144903 (2.0M) [application/x-gzip]\n",
      "Saving to: ‘kddcup.data_10_percent.gz.3’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  2%  362K 6s\n",
      "    50K .......... .......... .......... .......... ..........  4% 1.24M 4s\n",
      "   100K .......... .......... .......... .......... ..........  7%  220M 2s\n",
      "   150K .......... .......... .......... .......... ..........  9% 2.02M 2s\n",
      "   200K .......... .......... .......... .......... .......... 11% 11.1M 2s\n",
      "   250K .......... .......... .......... .......... .......... 14% 56.3M 1s\n",
      "   300K .......... .......... .......... .......... .......... 16% 2.09M 1s\n",
      "   350K .......... .......... .......... .......... .......... 19% 13.7M 1s\n",
      "   400K .......... .......... .......... .......... .......... 21% 63.1M 1s\n",
      "   450K .......... .......... .......... .......... .......... 23%  116M 1s\n",
      "   500K .......... .......... .......... .......... .......... 26% 70.5M 1s\n",
      "   550K .......... .......... .......... .......... .......... 28%  266M 1s\n",
      "   600K .......... .......... .......... .......... .......... 31% 2.15M 1s\n",
      "   650K .......... .......... .......... .......... .......... 33% 91.4M 1s\n",
      "   700K .......... .......... .......... .......... .......... 35%  263M 0s\n",
      "   750K .......... .......... .......... .......... .......... 38% 16.5M 0s\n",
      "   800K .......... .......... .......... .......... .......... 40% 73.7M 0s\n",
      "   850K .......... .......... .......... .......... .......... 42%  127M 0s\n",
      "   900K .......... .......... .......... .......... .......... 45% 87.2M 0s\n",
      "   950K .......... .......... .......... .......... .......... 47% 70.8M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 50%  143M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 52%  172M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 54% 87.3M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 57%  128M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 59% 85.4M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 62% 2.39M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 64% 77.5M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 66%  145M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 69%  119M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 71%  118M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 73%  103M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 76% 31.5M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 78% 90.6M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 81%  124M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 83%  176M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 85% 81.7M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 88%  163M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 90% 70.7M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 93%  239M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 95%  107M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 97%  111M 0s\n",
      "  2050K .......... .......... .......... .......... ....      100%  158M=0.3s\n",
      "\n",
      "2019-08-01 09:58:22 (6.92 MB/s) - ‘kddcup.data_10_percent.gz.3’ saved [2144903/2144903]\n",
      "\n",
      "gzip: kddcup.data_10_percent already exists;\tnot overwritten\n",
      "bash: line 4: BUCKET: command not found\n",
      "CommandException: \"cp\" command does not support provider-only URLs.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b\"wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\\ngunzip kddcup.data_10_percent.gz\\n#BUCKET='cloud-training-demos-ml'  # CHANGE\\nBUCKET = $(gcloud info --format='value(config.project)')[0]\\ngsutil cp kdd* gs://$BUCKET/\\nbq mk sparktobq\\n#wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\\n#gunzip kddcup.data_10_percent.gz\\n#BUCKET = $(gcloud info --format='value(config.project)')\\n#gsutil cp kdd* gs://$BUCKET/\\n\"' returned non-zero exit status 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-848fb2ca1ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\\ngunzip kddcup.data_10_percent.gz\\n#BUCKET='cloud-training-demos-ml'  # CHANGE\\nBUCKET = $(gcloud info --format='value(config.project)')[0]\\ngsutil cp kdd* gs://$BUCKET/\\nbq mk sparktobq\\n#wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\\n#gunzip kddcup.data_10_percent.gz\\n#BUCKET = $(gcloud info --format='value(config.project)')\\n#gsutil cp kdd* gs://$BUCKET/\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2356\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2358\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/lib/python3.5/dist-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b\"wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\\ngunzip kddcup.data_10_percent.gz\\n#BUCKET='cloud-training-demos-ml'  # CHANGE\\nBUCKET = $(gcloud info --format='value(config.project)')[0]\\ngsutil cp kdd* gs://$BUCKET/\\nbq mk sparktobq\\n#wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\\n#gunzip kddcup.data_10_percent.gz\\n#BUCKET = $(gcloud info --format='value(config.project)')\\n#gsutil cp kdd* gs://$BUCKET/\\n\"' returned non-zero exit status 1"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\n",
    "gunzip kddcup.data_10_percent.gz\n",
    "#BUCKET='cloud-training-demos-ml'  # CHANGE\n",
    "BUCKET = $(gcloud info --format='value(config.project)')[0]\n",
    "gsutil cp kdd* gs://$BUCKET/\n",
    "bq mk sparktobq\n",
    "#wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\n",
    "#gunzip kddcup.data_10_percent.gz\n",
    "#BUCKET = $(gcloud info --format='value(config.project)')\n",
    "#gsutil cp kdd* gs://$BUCKET/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reporting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import google.cloud.storage as gcs\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def create_report(BUCKET, gcsfilename, tmpdir):\n",
    "    \"\"\"\n",
    "    Creates report in gs://BUCKET/ based on contents in gcsfilename (gs://bucket/some/dir/filename)\n",
    "    \"\"\"\n",
    "    # connect to BigQuery\n",
    "    client = bigquery.Client()\n",
    "    destination_table = client.get_table('sparktobq.kdd_cup')\n",
    "    \n",
    "    # Specify table schema. Autodetect is not a good idea for production code\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"duration\", \"INT64\"),\n",
    "    ]\n",
    "    for name in ['protocol_type', 'service', 'flag']:\n",
    "        schema.append(bigquery.SchemaField(name, \"STRING\"))\n",
    "    for name in 'src_bytes,dst_bytes,wrong_fragment,urgent,hot,num_failed_logins'.split(','):\n",
    "        schema.append(bigquery.SchemaField(name, \"INT64\"))\n",
    "    schema.append(bigquery.SchemaField(\"unused_10\", \"STRING\"))\n",
    "    schema.append(bigquery.SchemaField(\"num_compromised\", \"INT64\"))\n",
    "    schema.append(bigquery.SchemaField(\"unused_12\", \"STRING\"))\n",
    "    for name in 'su_attempted,num_root,num_file_creations'.split(','):\n",
    "        schema.append(bigquery.SchemaField(name, \"INT64\")) \n",
    "    for fieldno in range(16, 41):\n",
    "        schema.append(bigquery.SchemaField(\"unused_{}\".format(fieldno), \"STRING\"))\n",
    "    schema.append(bigquery.SchemaField(\"label\", \"STRING\"))\n",
    "    job_config.schema = schema\n",
    "\n",
    "    # Load CSV data into BigQuery, replacing any rows that were there before\n",
    "    job_config.create_disposition = bigquery.CreateDisposition.CREATE_IF_NEEDED\n",
    "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    job_config.skip_leading_rows = 0\n",
    "    job_config.source_format = bigquery.SourceFormat.CSV\n",
    "    load_job = client.load_table_from_uri(gcsfilename, destination_table, job_config=job_config)\n",
    "    print(\"Starting LOAD job {} for {}\".format(load_job.job_id, gcsfilename))\n",
    "    load_job.result()  # Waits for table load to complete.\n",
    "    print(\"Finished LOAD job {}\".format(load_job.job_id))\n",
    "    \n",
    "    # connections by protocol\n",
    "    sql = \"\"\"\n",
    "        SELECT COUNT(*) AS count\n",
    "        FROM sparktobq.kdd_cup\n",
    "        GROUP BY protocol_type\n",
    "        ORDER by count ASC    \n",
    "    \"\"\"\n",
    "    connections_by_protocol = client.query(sql).to_dataframe()\n",
    "    connections_by_protocol.to_csv(os.path.join(tmpdir,\"connections_by_protocol.csv\"))\n",
    "    print(\"Finished analyzing connections\")\n",
    "    \n",
    "    # attacks plot\n",
    "    sql = \"\"\"\n",
    "                            SELECT \n",
    "                             protocol_type, \n",
    "                             CASE label\n",
    "                               WHEN 'normal.' THEN 'no attack'\n",
    "                               ELSE 'attack'\n",
    "                             END AS state,\n",
    "                             COUNT(*) as total_freq,\n",
    "                             ROUND(AVG(src_bytes), 2) as mean_src_bytes,\n",
    "                             ROUND(AVG(dst_bytes), 2) as mean_dst_bytes,\n",
    "                             ROUND(AVG(duration), 2) as mean_duration,\n",
    "                             SUM(num_failed_logins) as total_failed_logins,\n",
    "                             SUM(num_compromised) as total_compromised,\n",
    "                             SUM(num_file_creations) as total_file_creations,\n",
    "                             SUM(su_attempted) as total_root_attempts,\n",
    "                             SUM(num_root) as total_root_acceses\n",
    "                           FROM sparktobq.kdd_cup\n",
    "                           GROUP BY protocol_type, state\n",
    "                           ORDER BY 3 DESC\n",
    "    \"\"\"\n",
    "    attack_stats = client.query(sql).to_dataframe()\n",
    "    ax = attack_stats.plot.bar(x='protocol_type', subplots=True, figsize=(10,25))\n",
    "    ax[0].get_figure().savefig(os.path.join(tmpdir,'report.png'));\n",
    "    print(\"Finished analyzing attacks\")\n",
    "    \n",
    "    bucket = gcs.Client().get_bucket(BUCKET)\n",
    "    for blob in bucket.list_blobs(prefix='sparktobq/'):\n",
    "        blob.delete()\n",
    "    for fname in ['report.png', 'connections_by_protocol.csv']:\n",
    "        bucket.blob('sparktobq/{}'.format(fname)).upload_from_filename(os.path.join(tmpdir,fname))\n",
    "    print(\"Uploaded report based on {} to {}\".format(gcsfilename, BUCKET))\n",
    "\n",
    "\n",
    "def bigquery_analysis_cf(data, context):\n",
    "    # check that trigger is for a file of interest\n",
    "    bucket = data['bucket']\n",
    "    name = data['name']\n",
    "    if ('kddcup' in name) and not ('gz' in name):\n",
    "        filename = 'gs://{}/{}'.format(bucket, data['name'])\n",
    "        print(bucket, filename)\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            create_report(bucket, filename, tmpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "google-cloud-bigquery\n",
    "google-cloud-storage\n",
    "pandas\n",
    "matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# verify that the code in the CF works\n",
    "name='kddcup.data_10_percent'\n",
    "if 'kddcup' in name and not ('gz' in name):\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test that the function endpoint works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'domain': 'global', 'message': 'Not found: Table qwiklabs-gcp-576b6b9a967fad32:sparktobq.kdd_cup', 'reason': 'notFound'}]\n"
     ]
    }
   ],
   "source": [
    "# test that the function works\n",
    "import main as bq\n",
    "\n",
    "#BUCKET='cloud-training-demos-ml' # CHANGE\n",
    "BUCKET_list = !gcloud info --format='value(config.project)'\n",
    "BUCKET=BUCKET_list[0]\n",
    "\n",
    "try:\n",
    "    bq.create_report(BUCKET, 'gs://{}/kddcup.data_10_percent'.format(BUCKET), \"/tmp\")\n",
    "except Exception as e:\n",
    "    print(e.errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the cloud function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying function (may take a while - up to 2 minutes)...failed.\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.functions.deploy) OperationError: code=13, message=Failed to configure trigger GCS Bucket: qwiklabs-gcp-576b6b9a967fad32\n"
     ]
    }
   ],
   "source": [
    "!gcloud functions deploy bigquery_analysis_cf --runtime python37 --trigger-resource $BUCKET --trigger-event google.storage.object.finalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it out\n",
    "\n",
    "Copy the file to the bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BucketNotFoundException: 404 gs://qwiklabs-gcp-576b6b9a967fad32 bucket does not exist.\n",
      "CommandException: Encountered non-existent bucket during listing\n",
      "Copying file://kddcup.data_10_percent [Content-Type=application/octet-stream]...\n",
      "Caught ResumableUploadStartOverException for upload of file://kddcup.data_10_percent.\n",
      "Checking that bucket qwiklabs-gcp-576b6b9a967fad32 exists before retrying upload...\n",
      "Deleted tracker file /home/jupyter/.gsutil/tracker-files/upload_TRACKER_99d009f5de19b8ad80688322284d08a004eae2a4.ercent__JSON.url for resumable upload of file://kddcup.data_10_percent before retrying.\n",
      "BucketNotFoundException: 404 gs://qwiklabs-gcp-576b6b9a967fad32 bucket does not exist.\n"
     ]
    }
   ],
   "source": [
    "!gsutil rm -rf gs://$BUCKET/sparktobq\n",
    "!gsutil cp kddcup.data_10_percent gs://$BUCKET/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the Cloud Function is being run. You can do this from the [Cloud Functions](https://console.cloud.google.com/functions/) part of the GCP Console.\n",
    "\n",
    "Once the function is complete (in about 30 seconds), see if the output folder contains the report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BucketNotFoundException: 404 gs://qwiklabs-gcp-576b6b9a967fad32 bucket does not exist.\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://$BUCKET/sparktobq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
